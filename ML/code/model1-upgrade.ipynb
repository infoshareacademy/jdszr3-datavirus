{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules needed to handle data and encoding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, datafile,target):\n",
    "        #inicialization class object, and also creating the target dataset\n",
    "        self.df = pd.read_csv(datafile)\n",
    "        self.y=self.df[target]\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(self.y)\n",
    "        new_data = encoder.transform(self.y)\n",
    "        new_data.reshape(-1,1)\n",
    "    \n",
    "    \n",
    "    #create data frame with features, drop columns which are unnecessary or are target\n",
    "    def create_X(self, column):\n",
    "        self.X = self.df.drop(columns=column)\n",
    "    \n",
    "    #function which normalize categories number; for more than 4 categories in one column \n",
    "    #it calculates percentage value and for less than 5.5% category name is replaced with 'other'\n",
    "    def categories_normalization(self):\n",
    "        for column in self.X.columns:\n",
    "            if self.X[column].nunique()>4:\n",
    "                cat = self.X[column].unique()\n",
    "                number_for_cat = self.X[column].value_counts()\n",
    "                data_len = len(self.X[column])\n",
    "                list_to_replace = []\n",
    "                for i in range(len(cat)):\n",
    "                    cat_in_perc = round(number_for_cat[i]/data_len*100, 2)\n",
    "                    if cat_in_perc <= 5.5:\n",
    "                        list_to_replace.append(cat[i])\n",
    "                    else:\n",
    "                        pass\n",
    "                self.X[column].replace(to_replace=list_to_replace, value='other', inplace=True)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    #function which takes data frame, column name and scaler name and return data frame \n",
    "    #with encoded column using specified scaler        \n",
    "    def data_scaler(self, column_header, scaler_name):\n",
    "        column = np.array(self.X[column_header]).reshape(-1,1)\n",
    "        scaler = scaler_name()\n",
    "        scaler.fit(column)\n",
    "        new_data = scaler.transform(column)\n",
    "        self.X[column_header + \"_scal\"] = pd.Series(new_data[:,0])\n",
    "        self.X.drop(columns=column_header, inplace=True)\n",
    "    \n",
    "    #function which takes data frame, column name and encoder name and return data frame \n",
    "    #with encoded column using specified encoder\n",
    "    def data_encoder(self, encoding_function_name):\n",
    "        for column in self.X.columns:\n",
    "            if encoding_function_name==OneHotEncoder:\n",
    "                column_ = np.array(self.X[column]).reshape(-1,1)\n",
    "                encoder = encoding_function_name(sparse=False)\n",
    "                encoder.fit(column_)\n",
    "                categories = encoder.categories_\n",
    "                new_data = encoder.transform(column_)\n",
    "                for i in range(len(categories[0])):\n",
    "                    self.X[column + \"_\" + categories[0][i]] = pd.Series(new_data[:,i])\n",
    "                self.X.drop(columns=column, inplace=True)\n",
    "            elif encoding_function_name==LabelEncoder:\n",
    "                column_ = self.X[column]\n",
    "                encoder = encoding_function_name()\n",
    "                encoder.fit(column_)\n",
    "                new_data = encoder.transform(column_)\n",
    "                new_data.reshape(-1,1)\n",
    "                self.X[column + \"_enc\"] = pd.Series(new_data)\n",
    "                self.X.drop(columns=column, inplace=True)\n",
    "            elif encoding_function_name==OrdinalEncoder:\n",
    "                column_ = np.array(self.X[column]).reshape(-1,1)\n",
    "                encoder = encoding_function_name()\n",
    "                encoder.fit(column_)\n",
    "                new_data = encoder.transform(column_)\n",
    "                self.X[column + \"_enc\"] = pd.Series(new_data[:,0])\n",
    "                self.X.drop(columns=column, inplace=True)\n",
    "            else:\n",
    "                print(\"Encoder is not specified in function\")\n",
    "    \n",
    "\n",
    "    #function for chossing type of model and inicialization of model\n",
    "    def choose_model(self,model_type=None):\n",
    "        if model_type=='rf':\n",
    "            self.user_defined_model = RandomForestClassifier(oob_score=True)\n",
    "        elif model_type=='lg':\n",
    "            self.user_defined_model = LogisticRegression(random_state=42)\n",
    "        elif model_type=='svc':\n",
    "            self.user_defined_model = SVC(kernel='rbf')\n",
    "        elif model_type=='dt':\n",
    "            self.user_defined_model = DecisionTreeClassifier(max_depth=4 , min_samples_leaf=3)\n",
    "        elif model_type=='knn':\n",
    "            self.user_defined_model = KNeighborsClassifier(n_neighbors=2,leaf_size=20, algorithm='kd_tree',p=1)\n",
    "        else:\n",
    "            self.user_defined_model = RandomForestClassifier(oob_score=True)\n",
    "    \n",
    "\n",
    "    #function which split the target and features into test and training datasets, as inputs it get target, features and test_size\n",
    "    def split(self, test_size):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size = test_size, random_state = 42, shuffle=True)\n",
    "\n",
    "    #function for training model, which takes the training datasets\n",
    "    def fit(self):\n",
    "        self.model = self.user_defined_model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "    \n",
    "    #function for predictions, takes the test datasets\n",
    "    def predict(self):\n",
    "        self.result = self.model.predict(self.X_test)\n",
    "        #return result\n",
    "    \n",
    "    #checking score of chosen model for test data\n",
    "    def score(self):\n",
    "        m_score_train= self.model.score(self.X_train,self.y_train)\n",
    "        m_score_test = self.model.score(self.X_test, self.y_test)\n",
    "        return print( f\"Accuracy score for train set is {m_score_train}\" + \"\\n\" + f\"Accuracy score for test set is {m_score_test}\")\n",
    "    \n",
    "\n",
    "    #fucntion which added the rest function used for modeling, fit, predict and score - run one function instead of 3\n",
    "    def run_model(self):\n",
    "        self.fit()\n",
    "        self.predict()\n",
    "        self.score()\n",
    "\n",
    " #function for confusion matrix and  classification report\n",
    "    def matrix(self):\n",
    "        #conf_matrix=confusion_matrix(self.y_test,self.result)\n",
    "        #class_report=classification_report(self.y_test,self.result)\n",
    "        return f\"y_test: {self.y_test},y_pred: {self.result}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score for train set is 1.0\nAccuracy score for test set is 1.0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"y_test: 1971    e\\n6654    p\\n5606    p\\n3332    e\\n6988    p\\n       ..\\n7374    p\\n1149    e\\n4999    p\\n7497    p\\n3341    p\\nName: class, Length: 1625, dtype: object,y_pred: ['e' 'p' 'p' ... 'p' 'p' 'p']\""
      ]
     },
     "metadata": {},
     "execution_count": 207
    }
   ],
   "source": [
    "#Random forest model\n",
    "model_rf=Model(\"mushrooms.csv\",\"class\")\n",
    "model_rf.create_X([\"class\", \"gill-attachment\", \"stalk-root\", \"stalk-surface-above-ring\", \"stalk-surface-below-ring\", \n",
    "                      \"stalk-color-above-ring\", \"stalk-color-below-ring\", \"veil-type\", \"veil-color\", \"spore-print-color\"])\n",
    "model_rf.categories_normalization()\n",
    "model_rf.data_encoder(OneHotEncoder)\n",
    "model_rf.choose_model('rf')\n",
    "model_rf.split(0.2)\n",
    "#model_rf.fit()\n",
    "#model_rf.predict()\n",
    "#model_rf.score()\n",
    "\n",
    "model_rf.run_model()\n",
    "model_rf.matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score for train set is 0.9980654238480479\nAccuracy score for test set is 0.9983593109105825\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression model\n",
    "model_lr=Model(\"mushrooms.csv\",\"class\")\n",
    "model_lr.create_X([\"class\", \"gill-attachment\", \"stalk-root\", \"stalk-surface-above-ring\", \"stalk-surface-below-ring\", \n",
    "                      \"stalk-color-above-ring\", \"stalk-color-below-ring\", \"veil-type\", \"veil-color\", \"spore-print-color\"])\n",
    "model_lr.categories_normalization()\n",
    "model_lr.data_encoder(OneHotEncoder)\n",
    "model_lr.choose_model('lg')\n",
    "model_lr.split(0.3)\n",
    "#model_lr.fit()\n",
    "#model_lr.predict()\n",
    "#model_lr.score()\n",
    "\n",
    "model_lr.run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score for train set is 1.0\nAccuracy score for test set is 1.0\n"
     ]
    }
   ],
   "source": [
    "#SVC rbf model\n",
    "model_svc=Model(\"mushrooms.csv\",\"class\")\n",
    "model_svc.create_X([\"class\", \"gill-attachment\", \"stalk-root\", \"stalk-surface-above-ring\", \"stalk-surface-below-ring\", \n",
    "                      \"stalk-color-above-ring\", \"stalk-color-below-ring\", \"veil-type\", \"veil-color\", \"spore-print-color\"])\n",
    "model_svc.categories_normalization()\n",
    "model_svc.data_encoder(OneHotEncoder)\n",
    "model_svc.choose_model('svc')\n",
    "model_svc.split(0.3)\n",
    "#model_svc.fit()\n",
    "#model_svc.predict()\n",
    "#model_svc.score()\n",
    "\n",
    "model_svc.run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score for train set is 0.9996482588814632\nAccuracy score for test set is 0.9987694831829368\n"
     ]
    }
   ],
   "source": [
    "#KNN  model\n",
    "model_knn=Model(\"mushrooms.csv\",\"class\")\n",
    "model_knn.create_X([\"class\", \"gill-attachment\", \"stalk-root\", \"stalk-surface-above-ring\", \"stalk-surface-below-ring\", \n",
    "                      \"stalk-color-above-ring\", \"stalk-color-below-ring\", \"veil-type\", \"veil-color\", \"spore-print-color\"])\n",
    "model_knn.categories_normalization()\n",
    "model_knn.data_encoder(OneHotEncoder)\n",
    "model_knn.choose_model('knn')\n",
    "model_knn.split(0.3)\n",
    "#model_knn.fit()\n",
    "#model_knn.predict()\n",
    "#model_knn.score()\n",
    "\n",
    "model_knn.run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score for train set is 0.9887442842068238\nAccuracy score for test set is 0.9901558654634947\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree  model\n",
    "model_dt=Model(\"mushrooms.csv\",\"class\")\n",
    "model_dt.create_X([\"class\", \"gill-attachment\", \"stalk-root\", \"stalk-surface-above-ring\", \"stalk-surface-below-ring\", \n",
    "                      \"stalk-color-above-ring\", \"stalk-color-below-ring\", \"veil-type\", \"veil-color\", \"spore-print-color\"])\n",
    "model_dt.categories_normalization()\n",
    "model_dt.data_encoder(OneHotEncoder)\n",
    "model_dt.choose_model('dt')\n",
    "model_dt.split(0.3)\n",
    "#model_dt.fit()\n",
    "#model_dt.predict()\n",
    "#model_dt.score()\n",
    "\n",
    "model_dt.run_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "interpreter": {
   "hash": "0062e047125ebb5108b603169bc21de4af15d4941600a121f270f5b23dba400b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}